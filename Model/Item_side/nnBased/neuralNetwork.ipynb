{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input, Embedding, Flatten, dot, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Q1', 'Q2', 'Q3', 'Q4', 'Q5'],\n",
    "    'text': ['word1 word2 word3', 'text2 word1 word2 word3', 'text3', 'text4', 'text5'],\n",
    "    'accepted': [9, 17, 25, 38, 41],\n",
    "    'submission': [10, 20, 30, 40, 50],\n",
    "    'topics': ['arrays trees', 'linked list', 'trees dp', 'graphs trees', 'dp'],\n",
    "    'difficulty': ['Easy', 'Medium', 'Hard', 'Medium', 'Easy'],\n",
    "    'link': ['link1', 'link2', 'link3', 'link4', 'link5'],\n",
    "    'website': ['site1', 'site2', 'site3', 'site4', 'site5'],\n",
    "    'upvotes': [100, 200, 300, 400, 500],\n",
    "    'comments': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "label_encoder_name = LabelEncoder()\n",
    "df['name_encoded'] = label_encoder_name.fit_transform(df['name'])\n",
    "\n",
    "label_encoder_topics = LabelEncoder()\n",
    "df['topics_encoded'] = label_encoder_topics.fit_transform(df['topics'])\n",
    "\n",
    "\n",
    "df['popularity'] = df['accepted'] / df['submission']\n",
    "\n",
    "\n",
    "X = df[['name_encoded', 'topics_encoded']]\n",
    "Y = df['popularity']\n",
    "\n",
    "\n",
    "n_names = df['name_encoded'].nunique(),reverse=True\n",
    "n_topics = df['topics_encoded'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, dot, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "n_latent_factors = 5\n",
    "\n",
    "\n",
    "name_input = Input(shape=[1], name='name')\n",
    "name_embedding = Embedding(input_dim=n_names + 1, output_dim=n_latent_factors, name='name_embedding')(name_input)\n",
    "name_vec = Flatten(name='flatten_name')(name_embedding)\n",
    "\n",
    "\n",
    "topics_input = Input(shape=[1], name='topics')\n",
    "topics_embedding = Embedding(input_dim=n_topics + 1, output_dim=n_latent_factors, name='topics_embedding')(topics_input)\n",
    "topics_vec = Flatten(name='flatten_topics')(topics_embedding)\n",
    "\n",
    "\n",
    "dot_product = dot([name_vec, topics_vec], axes=1)\n",
    "\n",
    "\n",
    "dense_output = Dense(10, activation='relu')(dot_product)\n",
    "output = Dense(1)(dense_output)\n",
    "\n",
    "\n",
    "model = Model(inputs=[name_input, topics_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data (using name and topics as features)\n",
    "X_train = [df['name_encoded'], df['topics_encoded']]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x=X_train, y=Y, epochs=100, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User Specific Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input, Embedding, Flatten, dot, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Q1', 'Q2', 'Q3', 'Q4', 'Q5'],\n",
    "    'text': ['word1 word2 word3', 'text2 word1 word2 word3', 'text3', 'text4', 'text5'],\n",
    "    'accepted': [9, 17, 25, 38, 41],\n",
    "    'submission': [10, 20, 30, 40, 50],\n",
    "    'topics': ['arrays trees', 'linked list', 'trees dp', 'graphs trees', 'dp'],\n",
    "    'difficulty': ['Easy', 'Medium', 'Hard', 'Medium', 'Easy'],\n",
    "    'link': ['link1', 'link2', 'link3', 'link4', 'link5'],\n",
    "    'website': ['site1', 'site2', 'site3', 'site4', 'site5'],\n",
    "    'upvotes': [100, 200, 300, 400, 500],\n",
    "    'comments': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# Mocking additional data for number of attempts fetched from the backend\n",
    "attempts_data = {\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'attempts': [3, 7, 2, 10, 5]  # Example backend-fetched data\n",
    "}\n",
    "\n",
    "# Creating DataFrames\n",
    "df = pd.DataFrame(data)\n",
    "attempts_df = pd.DataFrame(attempts_data)\n",
    "\n",
    "# Merging attempts data into the main DataFrame\n",
    "df = pd.merge(df, attempts_df, on='id')\n",
    "\n",
    "# Label Encoding for Categorical Features\n",
    "label_encoder_name = LabelEncoder()\n",
    "df['name_encoded'] = label_encoder_name.fit_transform(df['name'])\n",
    "\n",
    "label_encoder_topics = LabelEncoder()\n",
    "df['topics_encoded'] = label_encoder_topics.fit_transform(df['topics'])\n",
    "\n",
    "# Calculating Popularity\n",
    "df['popularity'] = df['accepted'] / df['submission']\n",
    "\n",
    "# Sorting Based on Difficulty\n",
    "sorted_by_difficulty = df.sort_values(by='difficulty', key=lambda x: x.map({'Easy': 1, 'Medium': 2, 'Hard': 3}))\n",
    "\n",
    "# Sorting Based on Number of Attempts\n",
    "sorted_by_attempts = df.sort_values(by='attempts', ascending=False)\n",
    "\n",
    "# Creating Features and Target\n",
    "X = df[['name_encoded', 'topics_encoded']]\n",
    "Y = df['popularity']\n",
    "\n",
    "# Defining Number of Unique Values for Embedding\n",
    "n_names = df['name_encoded'].nunique()\n",
    "n_topics = df['topics_encoded'].nunique()\n",
    "\n",
    "# Latent Factors\n",
    "n_latent_factors = 5\n",
    "\n",
    "# Name Embedding\n",
    "name_input = Input(shape=[1], name='name')\n",
    "name_embedding = Embedding(input_dim=n_names + 1, output_dim=n_latent_factors, name='name_embedding')(name_input)\n",
    "name_vec = Flatten(name='flatten_name')(name_embedding)\n",
    "\n",
    "# Topics Embedding\n",
    "topics_input = Input(shape=[1], name='topics')\n",
    "topics_embedding = Embedding(input_dim=n_topics + 1, output_dim=n_latent_factors, name='topics_embedding')(topics_input)\n",
    "topics_vec = Flatten(name='flatten_topics')(topics_embedding)\n",
    "\n",
    "# Dot Product\n",
    "dot_product = dot([name_vec, topics_vec], axes=1)\n",
    "\n",
    "# Dense Layers\n",
    "dense_output = Dense(10, activation='relu')(dot_product)\n",
    "output = Dense(1)(dense_output)\n",
    "\n",
    "# Model Compilation\n",
    "model = Model(inputs=[name_input, topics_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Preparing Training Data\n",
    "X_train = [df['name_encoded'], df['topics_encoded']]\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(x=X_train, y=Y, epochs=100, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Outputs for Sorted DataFrames\n",
    "print(\"\\nData Sorted by Difficulty:\")\n",
    "print(sorted_by_difficulty[['id', 'name', 'difficulty']])\n",
    "\n",
    "print(\"\\nData Sorted by Number of Attempts:\")\n",
    "print(sorted_by_attempts[['id', 'name', 'attempts']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
